<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

  <title>Chapter 9</title>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <link href="../../css/ie10-viewport-bug-workaround.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="../../css/dashboard.css" rel="stylesheet">

  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
      <![endif]-->
       <style type="text/css">code{white-space: pre;}</style>
       <style type="text/css">.sidebar ul{padding-left: 10px;}</style>
       <script src="../../js/prism.js"></script>
       <link rel="stylesheet" href="../../css/prism.css">
       <script src="../../js/jquery.min.js"></script>    
       <script type="text/javascript" id="MathJax-script" async
	       src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
       </script>
       <script>
	 $(document).ready(function() {
  	     toc = $("#sidebar > ul > li > ul");
  	     sections = toc.children();   // <li>
  	     for(var i=0; i<sections.length; i++) {
  		 if ($(sections[i]).children().length == 1) { continue; }
  		 var first = sections[i].firstElementChild;  // <a>
  		 var last = sections[i].lastElementChild;
  		 var li = $("<li>");
  		 var details = $("<details>");
  		 var summary = $("<summary>");
  		 $(summary).append(first)
  		 $(details).append(summary);
  		 $(details).append(last);
  		 $(li).append(details);	
  		 $(sections[i]).replaceWith(li);
  	     }
	 });
	 </script>
       <link rel="stylesheet" href="../../css/pandoc.css">
       <script src="../../js/eBook.js"></script>
</head>
<body>

<nav class="navbar navbar-inverse navbar-fixed-top">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">HOME</a>
    </div>

    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="http://estat.me">eStat</a>
    </div>

    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="http://www.estat.me/estat/eStatU/index.html">eStatU</a>
    </div>

    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../../Distribution/index.html" target="_blank">Distributions</a>
    </div>

    <div id="navbar" class="navbar-collapse collapse">     
      <ul class="nav navbar-nav">
        <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Chapters<span class="caret"></span></a>
	  <ul class="dropdown-menu"> 
	   <li><a href="../chapter01/index.html">Chapter 1</a></li>
	   <li><a href="../chapter02/index.html">Chapter 2</a></li>
	   <li><a href="../chapter03/index.html">Chapter 3</a></li>
	   <li><a href="../chapter04/index.html">Chapter 3</a></li>
	   <li><a href="../chapter05/index.html">Chapter 5</a></li>
	   <li><a href="../chapter06/index.html">Chapter 6</a></li>
	   <li><a href="../chapter07/index.html">Chapter 7</a></li>
	   <li><a href="../chapter08/index.html">Chapter 8</a></li>
	   <li><a href="../chapter09/index.html">Chapter 9</a></li>
	   <li><a href="../chapter10/index.html">Chapter 10</a></li>
	   <li><a href="../chapter11/index.html">Chapter 11</a></li>
	   <li><a href="../chapter12/index.html">Chapter 12</a></li>
	  </ul>
	</li>
      </ul>
      <ul class="nav navbar-nav">
        <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Sections<span class="caret"></span></a>
	  <ul class="dropdown-menu"> 
                <li><a href="../chapter09/0901.html">9.1 Analysis of Variance for Experiments of Single Factor</a></li>
                <li><a href="../chapter09/090101.html">&nbsp;&nbsp;9.1.1 Multiple Comparison</a></li>
                <li><a href="../chapter09/090102.html">&nbsp;&nbsp;9.1.2 Residual Analysis</a></li>
                <li><a href="../chapter09/0902.html">9.2 Design of Experiments for Sampling</a></li>
                <li><a href="../chapter09/0902.html">&nbsp;&nbsp;9.2.1 Completely Randomized Design</a></li>
                <li><a href="../chapter09/090202.html">&nbsp;&nbsp;9.2.2 Randomized Block Design</a></li>
                <li><a href="../chapter09/0903.html">9.3 Analysis of Variance for Experiments of Two Factors</a></li>
                <li><a href="../chapter09/0904.html">9.4 Exercise</a></li>
	  </ul>
	</li>
      </ul>
    </div>

  </div>
</nav>

<div class="container-fluid">
  <div class="row">
    <div id="sidebar" class="col-sm-3 col-md2 sidebar">
      <ul>
	<li><a href=""></a>
	  <ul>
	    <li><a href="../chapter01/index.html">Chapter 1</a>
	      <ul>
                <li><a href="../chapter01/0101.html">1.1 Statistics and Data Science</a></li>
                <li><a href="../chapter01/0102.html">1.2 Population and Sample</a></li>
                <li><a href="../chapter01/0103.html">1.3 Variables and Data</a></li>
                <li><a href="../chapter01/0104.html">1.4 Softwares for Statistical Analysis</a></li>
                <li><a href="../chapter01/0105.html">1.5 Exercies</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter02/index.html">Chapter 2</a>
	      <ul>
                <li><a href="../chapter02/0201.html">2.1 Visualization of Qualitative Data</a></li>
                <li><a href="../chapter02/0202.html">2.2 Visualization of Summary Data</a></li>
                <li><a href="../chapter02/0202.html">&nbsp;&nbsp;2.2.1 Summary Data of Categorical Variable</a></li>
                <li><a href="../chapter02/020202.html">&nbsp;&nbsp;2.2.2 Summary Data of Categorical Variable with Group</a></li>
                <li><a href="../chapter02/0203.html">2.3 Visualization of Raw Data</a></li>
                <li><a href="../chapter02/0203.html">&nbsp;&nbsp;2.3.1 Raw Data of Categorical Variable</a></li>
                <li><a href="../chapter02/020302.html">&nbsp;&nbsp;2.3.2 Raw Data of Categorical Variable with Group</a></li>
                <li><a href="../chapter02/0204.html">2.4 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter03/index.html">Chapter 3</a>
	      <ul>
                <li><a href="../chapter03/0301.html">3.1 Visualization of Quantitative Data</a></li> 
                <li><a href="../chapter03/0302.html">3.2 Visualization of Single Quantitative Variable</a></li>
                <li><a href="../chapter03/0302.html">&nbsp;&nbsp;3.2.1 Visualization of Quantitative Data without Group</a></li>
                <li><a href="../chapter03/030202.html">&nbsp;&nbsp;3.2.2 Visualization of Quantitative Data with Group</a></li>
                <li><a href="../chapter03/0303.html">3.3 Visualization of Two Quantitative Variables</a></li>
                <li><a href="../chapter03/0304.html">3.4 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter04/index.html">Chapter 4</a>
	      <ul>
                <li><a href="../chapter04/0401.html">4.1 Frequency Table for Single Variable</a></li>
                <li><a href="../chapter04/0401.html">&nbsp;&nbsp;4.1.1 Frequency Table for Categorical Variable</a></li>
                <li><a href="../chapter04/040102.html">&nbsp;&nbsp;4.1.2 Frequency Table for Quantitative Variable</a></li>
                <li><a href="../chapter04/0402.html">4.2 Contingency Table for Two Variables</a></li>
                <li><a href="../chapter04/0402.html">&nbsp;&nbsp;4.2.1 Contingency Table for Two Categorical Variables</a></li>
                <li><a href="../chapter04/040202.html">&nbsp;&nbsp;4.2.2 Contingency Table for Two Quantitative Variables</a></li>
                <li><a href="../chapter04/0403.html">4.3 Summary Measures for Quantitative Variable</a></li>
                <li><a href="../chapter04/0403.html">&nbsp;&nbsp;4.3.1 Measures of Central Tendency</a></li>
                <li><a href="../chapter04/040302.html">&nbsp;&nbsp;4.3.2 Measures of Dispersion</a></li>
                <li><a href="../chapter04/0404.html">4.4 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter05/index.html">Chapter 5</a>
	      <ul>
                <li><a href="../chapter05/0501.html">5.1 Definition of Probability</a></li>
                <li><a href="../chapter05/0502.html">5.2 Calculation of Probability</a></li>
                <li><a href="../chapter05/0503.html">5.3 Discrete Random Variable</a></li>
		<li><a href="../chapter05/050301.html">&nbsp;&nbsp;5.3.1 Binomial Distribution</a></li>
		<li><a href="../chapter05/050302.html">&nbsp;&nbsp;5.3.2 Poissson Distribution</a></li>
		<li><a href="../chapter05/050303.html">&nbsp;&nbsp;5.3.3 Geometric Distribution</a></li>
		<li><a href="../chapter05/050304.html">&nbsp;&nbsp;5.3.4 Hypergeometric Distribution</a></li>
                <li><a href="../chapter05/0504.html">5.4 Continuous Random Variable</a></li>
		<li><a href="../chapter05/050401.html">&nbsp;&nbsp;5.4.1 Normal Distribution</a></li>
		<li><a href="../chapter05/050402.html">&nbsp;&nbsp;5.4.2 Exponential Distribution</a></li>
                <li><a href="../chapter05/0505.html">5.5 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter06/index.html">Chapter 6</a>
	      <ul>
                <li><a href="../chapter06/0601.html">6.1 Simple Random Sampling</a></li>
                <li><a href="../chapter06/0602.html">6.2 Sampling Distribution of Sample Means and Estimation of the Population Mean</a></li>
                <li><a href="../chapter06/0602.html">&nbsp;&nbsp;6.2.1 Sampling Distribution of Sample Means</a></li>
                <li><a href="../chapter06/060202.html">&nbsp;&nbsp;6.2.2 Estimation of the Population Mean</a></li>
                <li><a href="../chapter06/0603.html">6.3 Sampling Distribution of Sample Variances and Estimation of the Population Variance</a></li>
                <li><a href="../chapter06/0603.html">&nbsp;&nbsp;6.3.1 Sampling Distribution of Sample Variances</a></li>
                <li><a href="../chapter06/060302.html">&nbsp;&nbsp;6.3.2 Estimation of the Population Variance</a></li>
                <li><a href="../chapter06/0604.html">6.4 Sampling Distribution of Sample Proportions and Estimation of the Population Proportion</a></li>
                <li><a href="../chapter06/0604.html">&nbsp;&nbsp;6.4.1 Sampling Distribution of Sample Proportions</a></li>
                <li><a href="../chapter06/060402.html">&nbsp;&nbsp;6.4.2 Estimation of the Population Proportion</a></li>
                <li><a href="../chapter06/0605.html">6.5 Determination of the Sample Size  </a></li>
                <li><a href="../chapter06/0605.html">&nbsp;&nbsp;6.5.1 Determination of the Sample Size to Estimate the Population Mean </a></li>
                <li><a href="../chapter06/060502.html">&nbsp;&nbsp;6.5.2 Determination of the Sample Size to Estimate the Population Proportion</a></li> 
                <li><a href="../chapter06/0606.html">6.6 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter07/index.html">Chapter 7</a>
	      <ul>
                <li><a href="../chapter07/0701.html">7.1 Testing Hypothesis for a Population Mean</a></li>
                <li><a href="../chapter07/0702.html">7.2 Testing Hypothesis for a Population Variance</a></li>
                <li><a href="../chapter07/0703.html">7.3 Testing Hypothesis for a Population Proportion</a></li>
                <li><a href="../chapter07/0704.html">7.4 Testing Hypothesis with α and β simultaneously</a></li>
                <li><a href="../chapter07/0704.html">&nbsp;&nbsp;7.4.1 Type 2 Error and Power of a Test</a></li>
                <li><a href="../chapter07/070402.html">&nbsp;&nbsp;7.4.2 Testing Hypothesis with α and β</a></li>
                <li><a href="../chapter07/0705.html">7.5 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter08/index.html">Chapter 8</a>
	      <ul>
                <li><a href="../chapter08/0801.html">8.1 Testing Hypothesis for Two Population Means</a></li>
                <li><a href="../chapter08/0801.html">&nbsp;&nbsp;8.1.1 Two Independent Samples</a></li>
                <li><a href="../chapter08/080102.html">&nbsp;&nbsp;8.1.2 Paired Sample</a></li>
                <li><a href="../chapter08/0802.html">8.2 Testing Hypothesis for Two Population Variances</a></li>
                <li><a href="../chapter08/0803.html">8.3 Testing Hypothesis for Two Population Proportions</a></li>
                <li><a href="../chapter08/0804.html">8.4 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter09/index.html">Chapter 9</a>
	      <ul>
                <li><a href="../chapter09/0901.html">9.1 Analysis of Variance for Experiments of Single Factor</a></li>
                <li><a href="../chapter09/090101.html">&nbsp;&nbsp;9.1.1 Multiple Comparison</a></li>
                <li><a href="../chapter09/090102.html">&nbsp;&nbsp;9.1.2 Residual Analysis</a></li>
                <li><a href="../chapter09/0902.html">9.2 Design of Experiments for Sampling</a></li>
                <li><a href="../chapter09/0902.html">&nbsp;&nbsp;9.2.1 Completely Randomized Design</a></li>
                <li><a href="../chapter09/090202.html">&nbsp;&nbsp;9.2.2 Randomized Block Design</a></li>
                <li><a href="../chapter09/0903.html">9.3 Analysis of Variance for Experiments of Two Factors</a></li>
                <li><a href="../chapter09/0904.html">9.4 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter10/index.html">Chapter 10</a>
	      <ul>
                <li><a href="../chapter10/1001.html">10.1 Nonparametric Test for the Location Parameter of Single Population  </a></li>
                <li><a href="../chapter10/1001.html">&nbsp;&nbsp;10.1.1 Sign Test</a></li>
                <li><a href="../chapter10/100102.html">&nbsp;&nbsp;10.1.2 Wilcoxon Signed Rank Sum Test</a></li>
                <li><a href="../chapter10/1002.html">10.2 Nonparametric Test for Location Parameters of Two Populations</a></li>
                <li><a href="../chapter10/1002.html">&nbsp;&nbsp;10.2.1 Independent Samples: Wilcoxon Rank Sum Test</a></li>
                <li><a href="../chapter10/100202.html">&nbsp;&nbsp;10.2.2 Paired Samples: Wilcoxon Signed Rank Sum Test</a></li>
                <li><a href="../chapter10/1003.html">10.3 Nonparametric Test for Location Parameters of Several Populations</a></li>
                <li><a href="../chapter10/1003.html">&nbsp;&nbsp;10.3.1 Completely Randomized Design: Kruskal-Wallis Test</a></li>
                <li><a href="../chapter10/100302.html">&nbsp;&nbsp;10.3.2 Randomized Block Design: Friedman Test</a></li>
                <li><a href="../chapter10/1004.html">10.4 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter11/index.html">Chapter 11</a>
	      <ul>
                <li><a href="../chapter11/1101.html">11.1 Goodness of Fit Test</a></li>
                <li><a href="../chapter11/1101.html">&nbsp;&nbsp;11.1.1 Goodness of Fit Test for Categorical Distribution</a></li>
                <li><a href="../chapter11/110102.html">&nbsp;&nbsp;11.1.2 Goodness of Fit Test for Continuous Distribution</a></li>
                <li><a href="../chapter11/1102.html">11.2 Testing Hypothesis for Contingency Table</a></li>
                <li><a href="../chapter11/1102.html">&nbsp;&nbsp;11.2.1 Independence Test</a></li>
                <li><a href="../chapter11/110202.html">&nbsp;&nbsp;11.2.2 Homogeneity Test</a></li>
                <li><a href="../chapter11/1103.html">11.3 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter12/index.html">Chapter 12</a>
	      <ul>
                <li><a href="../chapter12/1201.html">12.1 Correlation Analysis</a></li>
                <li><a href="../chapter12/1202.html">12.2 Simple Linear Regression Analysis</a></li>
                <li><a href="../chapter12/1202.html">&nbsp;&nbsp;12.2.1 Simple Linear Regression Model</a></li>
                <li><a href="../chapter12/120202.html">&nbsp;&nbsp;12.2.2 Estimation of Regression Coefficient</a></li>
                <li><a href="../chapter12/120203.html">&nbsp;&nbsp;12.2.3 Goodness of Fit for Regression Line</a></li>
                <li><a href="../chapter12/120204.html">&nbsp;&nbsp;12.2.4 Analysis of Variance for Regression</a></li>
                <li><a href="../chapter12/120205.html">&nbsp;&nbsp;12.2.5 Inference for Regression</a></li>
                <li><a href="../chapter12/120206.html">&nbsp;&nbsp;12.2.6 Residual Analysis</a></li>
                <li><a href="../chapter12/1203.html">12.3 Multiple Linear Regression Analysis</a></li>
                <li><a href="../chapter12/1203.html">&nbsp;&nbsp;12.3.1 Multiple Linear Regression Model</a></li>
                <li><a href="../chapter12/120302.html">&nbsp;&nbsp;12.3.2 Estimation of Regression Coefficient</a></li>
                <li><a href="../chapter12/120303.html">&nbsp;&nbsp;12.3.3 Goodness of Fit for Regression and Analysis of Variance</a></li>
                <li><a href="../chapter12/120304.html">&nbsp;&nbsp;12.3.4 Inference for Multiple Linear Regression</a></li>
                <li><a href="../chapter12/1204.html">12.4 Exercise</a></li>
	      </ul>
	    </li>
	  </ul>
	</li>
      </ul>
    </div>
  </div>
</div>

<div class="col-sm-9 col-sm-offset-3 col-md-10 col-md-offset-2 main">


  <!--***********************************************************************-->
  <h2>Chapter 9. Testing Hypothesis for Several Population Means</h2> 
  <p>
  <table>
    <tr>
      <td><button type="button" style="width:160px" onclick="moveSection(90)">&#10094; &nbsp;&nbsp;<b>Previous</b></button></td>
      <td><button type="button" style="width:160px" onclick="moveSection(92)"><b>Next</b>&nbsp;&nbsp; &#10095;</button></td>
    </tr>
  </table>
  <p>
  <h3>9.1 Analysis of Variance for Single Factor Experiments</h3>
  <p>
  <h6>
      <a href="0901.pdf" target="_blank"><u>[presentation]</u></a>&nbsp;&nbsp;&nbsp;
      <a href="https://youtu.be/az6KJp26dFA" target="_blank"><u>[video]</u></a>
  </h6>
  <p>

    <div class="mainTable">
      In section 8.1, we discussed how to compare means of two populations using the testing hypothesis. This chapter 
      discusses how to compare means of several populations. There are many examples of comparing means of several 
      populations as follows: 
      <p>   
      <div class="textL30M10">
        -  Are average hours of library usage for each grade the same?
      </div>
      <div class="textL30M10">
        -  Are yields of three different rice seeds equal?
      </div>
      <div class="textL30M10">
        -  In a chemical reaction, are response rates the same at four different temperatures? 
      </div>
      <div class="textL30M10">
        -  Are average monthly wages of college graduates the same at three different cities? 
      </div>
      <p>
      The group variable used to distinguish groups of the population, such as the grade or the rice, is called a        factor. 
    </div>
      
    <div class="mainTableYellow">
      <b>Factor</b>
      <p>The group variable used to distinguish groups of the population is called a <b>factor</b>.   
    </div>
      
    <p>
    <div class="mainTable">
      This section describes the one-way analysis of variance (ANOVA) which compares population means when there is a 
      single factor. Section 9.2 describes how the experiment is designed to extract sample data. Section 9.3 describes 
      the two-way  ANOVA to compare several population means when there are two factors. Let's take a look at the 
      following example.
    </div>
    <p>
       
    <!------------------------------------------------------------------------------------------------->
    <div class="mainTableGrey">
      <b>Example 9.1.1</b>
      In order to compare the English proficiency of each grade at a university, samples were randomly selected from 
      each grade to take the same English test, and data are as in Table 9.1.1. The last row is a calculation of 
      the average \({\overline y}_{1\cdot}\), \({\overline y}_{2\cdot}\), \({\overline y}_{3\cdot}\), \({\overline y}_{4\cdot}\) for each grade.
      <p>
        <div class="textLeft">Table 9.1.1  English Proficiency Score by Grade</div>
      <p>
      <table style="width:600px"> 
         <tr> 
           <th style="width:100px"> Socre</th>
           <th>Student 1</th>
           <th>Student 2</th>
           <th>Student 3</th>
           <th>Student 4</th>
           <th>Student 5</th>
           <th>Student 6</th>
           <th style="width:100px">Student Average</th>
         </tr>
         <tr> 
           <td class="tdCenter">Grade 1</td>
           <td class="tdCenter">81</td>
           <td class="tdCenter">75</td>
           <td class="tdCenter">69</td>
           <td class="tdCenter">90</td>
           <td class="tdCenter">72</td>
           <td class="tdCenter">83</td>
           <td class="tdCenter">\({\overline y}_{1\cdot}\)=78.3</td>
         </tr>
         <tr>
           <td class="tdCenter">Grade 2</td>
           <td class="tdCenter">65</td>
           <td class="tdCenter">80</td>
           <td class="tdCenter">73</td>
           <td class="tdCenter">79</td>
           <td class="tdCenter">81</td>
           <td class="tdCenter">69</td>
           <td class="tdCenter">\({\overline y}_{2\cdot}\)=74.5</td>
         </tr>
         <tr>
           <td class="tdCenter">Grade 3</td>
           <td class="tdCenter">72</td>
           <td class="tdCenter">67</td>
           <td class="tdCenter">62</td>
           <td class="tdCenter">76</td>
           <td class="tdCenter">80</td>
           <td class="tdCenter"></td>  
           <td class="tdCenter">\({\overline y}_{3\cdot}\)=71.4</td>
         </tr>
         <tr> 
           <td class="tdCenter">Grade 4</td> 
           <td class="tdCenter">89</td>
           <td class="tdCenter">94</td>
           <td class="tdCenter">79</td>
           <td class="tdCenter">88</td>
           <td class="tdCenter"></td>  
           <td class="tdCenter"></td>  
           <td class="tdCenter">\({\overline y}_{4\cdot}\)=87.5</td>
         </tr>
      </table>
      <p class="textLeft">[Ex] ⇨ eBook ⇨ EX090101_EnglishScoreByGrade.csv. 
      <p>
      <div class="textL20M20">
        1) Using 『eStat』 , draw a dot graph of test scores for each grade and compare their averages.
      </div>
      <div class="textL20M20">
        2) We want to test a hypothesis whether average scores of each grade are the same or not. Set up a null 
           hypothesis and an alternative hypothesis.
      </div>
      <div class="textL20M20">
        3) Apply the one-way analysis of variances to test the hypothesis in question 2).
      </div>
      <div class="textL20M20">
        4) Use 『eStat』 to check the result of the ANOVA test.
      </div>
      <p>
      <b>Answer</b>
      <p>
      <div class="textL20M20">
        1) If you draw a dot graph of English scores by each grade, you can see whether scores of each grade are similar. 
           If you plot the 95% confidence interval of the population mean studied in Chapter 6 on each dot graph, you can 
           see a more detailed comparison. 
        <br> 
           In order to draw a dot graph with data shown in Table 9.1.1 using  『eStat』 , enter data on the sheet 
           and set variable names to 'Grade' and 'Score' as shown in &lt;Figure 9.1.1&gt;. In the variable selection box 
           which appears by clicking the ANOVA icon  on the main menu of 『eStat』 , select 'Analysis Var' as ‘Score’ 
          and 'By Group' as ‘Grade’. The dot graph of English scores by each grade and the 95% confidence interval are displayed as shown in &lt;Figure 9.1.2&gt;.
      </div>
      <p>
      <table class="width:650px">
        <tr>
          <td>
            <input class="qrBtn" type="image" src="../../QR/EX090101.svg" onclick="window.open(addrStr[27])">
          </td>
          <td>
            <img class="imgFig600400" src="../../Figure/Fig090101.png">
            <div class="figText">&lt;Figure 9.1.1&gt; 『eStat』 data input for ANOVA</div>
          </td>
        </tr>
      </table>
      <p>
        <img class="imgFig600400" src="../../Figure/Fig090102.svg">
        <div class="figText">&lt;Figure 9.1.2&gt; 95% Confidence Interval by grade</div>
      <p>
      <div class="textL20">
          To review the normality of the data, pressing the [Histogram] button under this graph (&lt;Figure 9.1.3&gt;) will 
          draw the histogram and normal distribution together, as shown in &lt;Figure 9.1.4&gt;.
      </div>
        <p>
          <img class="imgFig600400" src="../../Figure/Fig090103.png">
          <div class="figText">&lt;Figure 9.1.3&gt; Options of ANOVA</div>
        <p>
          <img class="imgFig600400" src="../../Figure/Fig090104.svg">
          <div class="figText">&lt;Figure 9.1.4&gt; Histogram of English score by grade</div>
        <p><br>
        <div class="textL20">
          &lt;Figure 9.1.2&gt; shows sample means as \({\overline y}_{1\cdot}\)= 78.3,
          \({\overline y}_{2\cdot}\) = 74.5, \({\overline y}_{3\cdot}\) = 71.4,
          \({\overline y}_{1\cdot}\) = 87.5. The sample mean of the 4th grader is 
          relatively large and the order of the sample means in English is 
          \({\overline y}_{3\cdot} \lt {\overline y}_{2\cdot} \lt {\overline y}_{1\cdot} \lt {\overline y}_{4\cdot} \).
          \({\overline y}_{2\cdot}\) and \({\overline y}_{3\cdot}\) are similar, but \({\overline y}_{4\cdot}\)  is 
          much greater than the other three. Therefore, it can be expected that the population mean 
          \(\mu_{2}\) and \(\mu_{3}\) would be the same and  \(\mu_{4}\) will differ from three other population means. However, we need to test whether this difference by sample 
          means is statistically significant.
        </div>
        <p>
      <div class="textL20M20">
        2) In this example, the null hypothesis to test is that population means of English scores of the four grades 
           are all the same, and the alternative hypothesis is that population means of the English scores are not the same. 
           In other words, if  are the population means of English scores for each grade, the hypothesis to test can be written as follows, 
        <p>
        <div class="textL30">
          Null hypothesis \(\small \qquad \qquad \; H_0\): \(\mu_1 = \mu_2 = \mu_3 = \mu_4\) 
        </div>
        <div class="textL30">
          Alternative hypothesis \( \quad \small H_1\): at least one pair of \(\mu_i\) is not the same
        </div>
      </div>
      <p>
      <div class="textL20M20">
        3) A measure that can be considered first as a basis for testing differences in multiple sample means would be 
           the distance from each mean to the overall mean. In other words, if the overall sample mean for all 21 students 
           is expressed as \(\overline y_{\cdot \cdot}\), the distance from each sample mean to the overall mean is as follows when the number of samples 
           in each grade is weighted. This distance is called the between sum of squares (SSB) or the treatment sum of squares (SSTr). 
        <p>
        <div class="textL30">
          \(\small SSTr = 6(78.3 - {\overline y}_{\cdot \cdot})^2 + 6(74.5 - {\overline y}_{\cdot \cdot})^2 + 5(71.4 - {\overline y}_{\cdot \cdot})^2 + 4(87.5 - {\overline y}_{\cdot \cdot})^2  \) = 643.633
        </div>
      </div>
      <p>
      <div class="textL20">
           If the distance \(\small SSTr\) is close to zero, all sample means of English scores for four grades are similar.
        <p>     
           However, this treatment sum of squares can be larger if the number of populations increases. 
           It requires modification to become a test statistic to determine whether several population means are equal. 
           The distance from each observation to its sample mean of the grade is called the within sum of squares (SSW) or 
           the error sum of squares (SSE) as defined below.
        <p>
        <div class="textL30">
           \(\small SSE = (81 -{\overline y}_{1 \cdot})^2 + (75 -{\overline y}_{1 \cdot})^2 + \cdots + (83 -{\overline y}_{1 \cdot})^2\) <br>
           \(\small \qquad + (65 -{\overline y}_{2 \cdot})^2 + (80 -{\overline y}_{2 \cdot})^2 + \cdots + (69 -{\overline y}_{2 \cdot})^2\) <br>   
           \(\small \qquad + (72 -{\overline y}_{3 \cdot})^2 + (67 -{\overline y}_{3 \cdot})^2 + \cdots + (80 -{\overline y}_{3 \cdot})^2\) <br>
           \(\small \qquad + (89 -{\overline y}_{4 \cdot})^2 + (94 -{\overline y}_{4 \cdot})^2 + \cdots + (88 -{\overline y}_{4 \cdot})^2\) <br>  
           =  839.033
        </div>
        <p>
           If population distributions of English scores in each grade follow normal distributions and their variances are 
           the same, the following test statistic has the  distribution.
        <div class="textL30">
          \(\small  F_{0} = \frac { \frac{SSTr}{(4-1)} } { \frac{SSE}{(21-4)} } \)
        </div>
        <p>
           This statistic can be used to test whether population English scores of four grades are the same or not. In 
           the test statistic, the numerator \(\frac{SSTr}{4-1}\) is called the treatment mean square (MSTr) which implies a variance between 
           grade means. The denominator \(\frac{SSE}{21-4}\) is called the error mean square (MSE) which implies a variance within each grade. 
           Thus, the above test statistics are based on the ratio of two variances which is why the test of multiple 
           population means is called an analysis of variance (ANOVA).
           <p>
           Calculated test statistic which is the observed \(\small F\) value, \(\small F_{0}\) , using data of English scores for each grade is as follows.
        <p>
        <div class="textLeft">
          \( F_{0} = \frac { \frac{SSTr}{(4-1)} } { \frac{839.033}{(21-4)} } = \frac { \frac{643.633}{(4-1)} } { \frac{SSE}{(21-4)} } = 4.347\)
        </div>
        <p>
           Since \(\small F_{3,17; 0.05}\) = 3.20, the null hypothesis that population means of English scores of each grade are the same,
           \(\small H_0 : \mu_1 = \mu_2 = \mu_3 = \mu_4 \) , is rejected at the 5% significance level. 
           In other words, there is a difference in population means of English scores of each grade. 
           <p>  
           The following ANOVA table provides a single view of the above calculation.
      </div>
      <p>
            <table class="width:600px">
                <tr> 
                  <th>Factor</th>
                  <th>Sum of Squares</th>
                  <th>Degree of freedom</th>
                  <th>Mean Squares</th>
                  <th>F ratio</th>
                </tr>
                <tr> 
                  <td class="tdCenter">Treatment</td>
                  <td class="tdCenter">SSTr=643.633</td>
                  <td class="tdCenter">4-1</td>
                  <td class="tdCenter">MSTr=\(\frac{643.633}{3}\)</td>
                  <td class="tdCenter">\(F_0 = 4.347\)</td>
                </tr>
                <tr> 
                  <td class="tdCenter">Error</td>
                  <td class="tdCenter">SSE= 839.033</td>
                  <td class="tdCenter">21-4</td>
                  <td class="tdCenter">MSE=\(\frac{839.033}{17}\)</td>
                  <td class="tdCenter"></td>
                </tr>
                <tr> 
                  <td class="tdCenter">Total</td>
                  <td class="tdCenter">SST = 1482.666</td>
                  <td class="tdCenter">20</td>
                  <td class="tdCenter"></td>
                  <td class="tdCenter"></td>
                </tr>
             </table>
           <p>

      <div class="textL20M20">
        4) In &lt;Figure 9.1.3&gt;, if you select the significance level of 5%, confidence level of 95%, 
           and click [ANOVA F test] button, a graph showing the location of the test statistic in the F distribution
           is appeared as shown in &lt;Figure 9.1.5&gt;. Also, in the Log Area, the mean and confidence interval tables 
           and test result for each grade are appeared as in&lt;Figure 9.1.6&gt;.
      </div>
      <p>
      <div class="textL20">
          <img class="imgFig600400" src="../../Figure/Fig090105.svg">
          <div class="figText">&lt;Figure 9.1.5&gt;  『eStat』  ANOVA F test</div>
        <p>
          <img class="imgFig600400" src="../../Figure/Fig090106.png">
          <div class="figText">&lt;Figure 9.1.6&gt;  『eStat』 Basic Statistics and ANOVA table</div>
        <p><br>
           The analysis of variance is also possible using 『eStatU』. Entering the data as &lt;Figure 9.1.7&gt; 
           and clicking the [Execute] button will have the same result as in &lt;Figure 9.1.5&gt;.
        <p>
          <img class="imgFig600400" src="../../Figure/Fig090107.png">
          <div class="figText">&lt;Figure 9.1.7&gt; ANOVA data input at 『eStatU』</div>
      </div> 
    </div>
    <!------------------------------------------------------------------------------------------------->
    <p>      
 
    <div class="mainTable">
      The above example refers to two variables, the English score and grade. The variable such as the English score is 
      called as an analysis variable or a response variable. The response variable is mostly a continuous variable. The 
      variable used to distinguish populations such as the grade is called a group variable or a factor variable which 
      is mostly a categorical variable. Each value of a factor variable Is called a level of the factor and the number 
      of these levels is the number of populations to be compared. In the above example, the factor has four levels, 
      1st, 2nd, 3rd and 4th grade. The term 'response' or 'factor' was originated to analyze data through experiments 
      in engineering, agriculture, medicine and pharmacy. 
      <p>
      The analysis of variance method that examines the effect of single factor on the response variable is called the 
      one-way ANOVA. Table 9.1.2 shows the typical data structure of the one-way ANOVA when the number of levels of a 
      factor is \(k\) and the numbers of observation at each level are \(n_1 , n_2 , ... , n_k\).
    </div>
    <p>
      <div class="textLeft">Table 9.1.2  Notation of the one-way ANOVA</div>  
    <p>
      <table style="width:400px"> 
         <tr> 
           <th style="width:100px">Factor</th>
           <th>Observed values of sample</th>
           <th style="width:100px">Average</th>
         </tr>
         <tr> <td class="tdCenter">Level 1</td>    <td class="tdCenter">\(Y_{11} \; Y_{12}\; \cdots \;Y_{1n_1} \)</td> <td class="tdCenter">\(\overline Y_{1\cdot}\)</td> </tr>
         <tr> <td class="tdCenter">Level 2</td>    <td class="tdCenter">\(Y_{21} \; Y_{22}\; \cdots \;Y_{2n_2} \)</td> <td class="tdCenter">\(\overline Y_{2\cdot}\)</td> </tr>
         <tr> <td class="tdCenter">\(\cdots\)</td> <td class="tdCenter">\(\cdots\)</td>                      <td class="tdCenter">\(\cdots\)</td> </tr>
         <tr> <td class="tdCenter">Level k</td>    <td class="tdCenter">\(Y_{k1} \; Y_{k2}\; \cdots \;Y_{kn_k} \)</td> <td class="tdCenter">\(\overline Y_{k\cdot}\)</td> </tr>
      </table>
    <p>    
           
    <div class="mainTable">
      Statistical model for the one-way analysis of variance is given as follows: 
        $$
         \begin{align}
           Y_{ij} &= \mu_i + \epsilon_{ij} \\
                  &= \mu + \alpha_i + \epsilon_{ij}, i=1,2,...,k; j=1,2,..., n_i  \\
         \end{align}
        $$
      \(Y_{ij}\) represents the \(j^{th}\) observed value of the response variable for the \(i^{th}\) level of factor. 
      The population mean of the \(i^{th}\) level, \(\mu_{i}\), is represented as \(\mu + \alpha_{i}\) where \(\mu\)
      is the mean of entire population and \(\alpha_{i}\) is the effect of \(i^{th}\) level for the response 
      variable. \(\epsilon_{ij}\) denotes an error term of the \(j^{th}\) observation 
      for the \(i^{th}\) level and the all error terms are assumed independent of each other and follow 
      the same normal distribution with the mean 0 and variance \(\sigma^{2}\).   
      <p>
      The error term \(\epsilon_{ij}\) is a random variable in the response variable due to reasons other than levels of the factor. 
      For example, in the English score example, differences in English performance for each grade can be caused 
      by other variables besides the variables of grade, such as individual English study hours, gender and IQ. 
      However, by assuming that these changes are relatively small compared to changes due to differences in grade, the 
      error term can be interpreted as the sum of these various reasons. 
      <p>
      The hypothesis to test can be represented using \(\alpha_{i}\) instead of \(\mu_{i}\) as follows: 
        <p>
        <div class="textL20">
          Null hypothesis \(\qquad \quad \;\;\; H_0\): \(\alpha_1 = \alpha_2 = \alpha_3 = \alpha_4\) <br>
        </div>
        <div class="textL20">
          Alternative hypothesis \( \quad H_1\): at least one \(\alpha_i\) is not equal to 0
        </div>
       <p>
       In order to test the hypothesis, the analysis of variance table as Table 9.1.3 is used. 
    </div>
           <p>
             <div class="textLeft"> Table 9.1.3  Analysis of variance table of the one-way ANOVA</div>
           <p>
             <table style="width:600px"> 
                <tr> 
                  <th>Factor</th>
                  <th>Sum of Squares</th>
                  <th>Degree of freedom</th>
                  <th>Mean Squares</th>
                  <th>F ratio</th>
                </tr>
                <tr> 
                  <td class="tdCenter">Treatment</td>
                  <td class="tdCenter">SSTr</td>
                  <td class="tdCenter">\(k-1\)</td>
                  <td class="tdCenter">MSTr=\(\frac{SSTr}{k-1}\)</td>
                  <td class="tdCenter">\(F_0 = \frac{MSTr}{MSE}\)</td>
                </tr>
                <tr> 
                  <td class="tdCenter">Error</td>
                  <td class="tdCenter">SSE</td>
                  <td class="tdCenter">\(n-k\)</td>
                  <td class="tdCenter">MSE=\(\frac{SSE}{n-k}\)</td>
                  <td class="tdCenter"></td>
                </tr>
                <tr> 
                  <td class="tdCenter">Total</td>
                  <td class="tdCenter">SST</td>
                  <td class="tdCenter">\(n-1\)</td>
                  <td class="tdCenter"></td>
                  <td class="tdCenter"></td>
                </tr>
             </table>
           <p>
        <div class="textL20">
          \(\qquad n = \sum_{i=1}^{n} \; n_i\) <br>
        </div>
        <p>
    <div class="mainTable">
       The three sum of squares for the variance analysis can be described as follows: For an explanation, first define 
       the following statistics:
       <p>
       <div class="textL20">
          \({\overline Y}_{i \cdot}     \; \) Mean of observations at the \(i^{th}\) level <br>
          \({\overline Y}_{\cdot \cdot} \; \) Mean of total observations 
       </div>
       <p>
       <b>SST</b> = \(\sum_{i=1}^{k} \sum_{j=1}^{n_i} ( Y_{ij} - {\overline Y}_{\cdot \cdot} )^2 \;\) : <br>
       The sum of squared distances between observed values of the response variable and the mean of total observations 
       is called the <b>total sum of squares</b> (SST). 
       <p>
       <b>SSTr</b> = \(\sum_{i=1}^{k} \sum_{j=1}^{n_i} ( {\overline Y}_{i \cdot} - {\overline Y}_{\cdot \cdot} )^2 \;\) : <br>
       The sum of squared distances between the mean of each level and the mean of total observations is called the 
       <b>treatment sum of squares</b> (SSTr). It represents the variation between level means. 
       <p>
       <b>SSE</b> = \(\sum_{i=1}^{k} \sum_{j=1}^{n_i} ( {Y}_{ij} - {\overline Y}_{i \cdot} )^2 \;\) : <br>
       The sum of squared distances between observations of the \(i^{th}\) level and the mean of the \(i^{th}\) level is referred to as 
       'within variation,' and is called the <b>error sum of squares</b> (SSE).
       <p>
       The degree of freedom of each sum of squares is determined by the following logic: 
       The SST consists of \(n\) number of squares, \(( Y_{ij} - {\overline Y}_{\cdot \cdot} )^2\), 
       but \( {\overline Y}_{\cdot \cdot} \) should be calculated first, before SST is calculated,
       and hence the degree of freedom of SST is \(n-1\). The SSE consists of \(n\) number of squares,
       \(( {Y}_{ij} - {\overline Y}_{i \cdot} )^2 \), but the  number of values, 
       \({\overline Y}_{1 \cdot}, {\overline Y}_{2 \cdot}, ... , {\overline Y}_{k \cdot}\) 
       should be calculated first, before SSE is calculated, and hence the degree of freedom of SSE is \(n-k\).
       The degree of freedom of SSTr is calculated as the degree of freedom of SST minus the degree of freedom of SSE which is .
       In the one-way analysis of variance, the following facts are always established:
    </div>

    <p>    
    <div class="mainTableYellow">
       <b>Partition of sum of squares and degrees of freedom
          <p>
          Sum of squares:  SST = SSTr + SSE     <br>	
          Degrees of freedom:  \((n-1) = (k-1) + (n-k)\) 
       </b>	
    </div>
    <p>    
 
    <div class="mainTable">
      The sum of squares divided by the corresponding degrees of freedom is referred to as the mean squares and Table 
      9.1.3 defines the treatment mean squares (MSTr) and error mean squares (MSE).  As in the meaning of the sum of 
      squares, the treatment mean square implies the average variation between each level of the factor, and the error 
      mean square implies the average variation within observations in each level. Therefore, if MSTr is relatively 
      much larger than MSE, we can conclude that the population means of each level, \(\mu_i\), are not the same. So by what 
      criteria can you say it is relatively much larger?
      <p>
      The calculated \(F\) value, \(F_0\), in the last column of the ANOVA table represents the relative size of MSTr and MSE. If 
      the assumptions of \(\epsilon_{ij}\) based on statistical theory are satisfied, and if the null hypothesis
      \(\small H_0 : \alpha_1 = \alpha_2 = \cdots = \alpha_k \) = 0  is true, then the 
      below test statistic follows a F distribution with degrees of freedoms \(k-1\) and \(n-k\). 
      $$
        F_{0} = \frac { \frac{SSTr}{(k-1)} } { \frac{SSE}{(n-k)} } 
      $$
      Therefore, when the significance level is \(\alpha\) for a test, if the calculated value \(F_0\) is greater 
      than the value of \(F_{k-1,n-k; &alpha;}\), then the null hypothesis is rejected. That is, 
      it is determined that the population means of each factor level are not all the same. 
    </div>
            
    <p>    
    <div class="mainTableYellow">
      <b>One-way analysis of variance  test
        <p>
        <div class="textL20">
          Null hypothesis \(\qquad \qquad \; H_0\): \(\alpha_1 = \alpha_2 = \alpha_3 = \alpha_4\) <br>
        </div>
        <div class="textL20">
          Alternative hypothesis \( \quad H_1\): at least one \(\alpha_i\) is not equal to 0
        </div>
        <div class="textL20">
          Test Statistic \(\;\; F_{0} = \frac { \frac{SSTr}{(k-1)} } { \frac{SSE}{(n-k)} } \) 
        </div>
        <div class="textL20">
          Decision Rule If \(\;\; F_0 > F_{k-1,n-k; &alpha;} \), then reject \(H_0\)
        </div>
      </b>
      <p>
       (Note:  『eStat』 calculates the \(p\)-value of this test. Hence if the \(p\)-value is smaller than 
       the significance level \(\alpha\), then reject the null hypothesis. )
    </div>
    <p>   	
       
    <!------------------------------------------------------------------------------------------------->
    <div class="mainTablePink">
      <table class="width:650px">
        <tr>
          <td>
            <input class="qrBtn" type="image" src="../../QR/PR090101.svg" onclick="window.open(addrStr[65])">
          </td>
          <td>
            <b>Practice 9.1.1</b> 
            <b>(Plant Growth by Condition)</b><br>
            Results from an experiment to compare yields (as measured by dried weight of plants) obtained under a control 
            (leveled ‘ctrl’) and two different treatment conditions (leveled ‘trt1’ and ‘trt2’). The weight data with 
            30 observations on control and two treatments (‘crtl’, ‘trt1’, ‘trt2’), are saved at the following location 
            of  『eStat』. Answer the followings using 『eStat』 ,
            <p>
            <div class="textLeft"> [Ex] ⇨ eBook ⇨ PR090101_Rdatasets_PlantGrowth.csv </div>
            <p> 
            <div class="textL20M20">
              1) Draw a dot graph of weights for each control and treatments. 
            </div>
            <div class="textL20M20">
              2) Test a hypothesis whether the weights are the same or not. Use the 5% significance level. 
            </div>
          </td>
        </tr>
      </table>
    </div>
    <!------------------------------------------------------------------------------------------------->
    <p>   
       
  <table>
    <tr>
      <td><button type="button" style="width:160px" onclick="moveSection(90)">&#10094; &nbsp;&nbsp;<b>Previous</b></button></td>
      <td><button type="button" style="width:160px" onclick="moveSection(92)"><b>Next</b>&nbsp;&nbsp; &#10095;</button></td>
    </tr>
  </table>

</div>

    
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="https://maxcdn.bootstrapcdn.com/js/ie10-viewport-bug-workaround.js"></script>
    <script>
        //document.getElementById('sidebar').getElementsByTagName('ul')[0].className += "nav nav-sidebar";
        
        /* ajust the height when click the toc
           the code is from https://github.com/twbs/bootstrap/issues/1768
        */
        var shiftWindow = function() { scrollBy(0, -50) };
        window.addEventListener("hashchange", shiftWindow);
        function load() { if (window.location.hash) shiftWindow(); }
        
        /*add Bootstrap styles to tables*/
        var tables = document.getElementsByTagName("table");
        for(var i = 0; i < tables.length; ++i){
            tables[i].className += "table table-bordered table-hover";
        }
    </script>

</body>
</html>

