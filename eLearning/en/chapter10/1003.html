<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

  <title>Chapter 10</title>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <link href="../../css/ie10-viewport-bug-workaround.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="../../css/dashboard.css" rel="stylesheet">

  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
      <![endif]-->
       <style type="text/css">code{white-space: pre;}</style>
       <style type="text/css">.sidebar ul{padding-left: 10px;}</style>
       <script src="../../js/prism.js"></script>
       <link rel="stylesheet" href="../../css/prism.css">
       <script src="../../js/jquery.min.js"></script>    
       <script type="text/javascript" id="MathJax-script" async
	       src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
       </script>
       <script>
	 $(document).ready(function() {
  	     toc = $("#sidebar > ul > li > ul");
  	     sections = toc.children();   // <li>
  	     for(var i=0; i<sections.length; i++) {
  		 if ($(sections[i]).children().length == 1) { continue; }
  		 var first = sections[i].firstElementChild;  // <a>
  		 var last = sections[i].lastElementChild;
  		 var li = $("<li>");
  		 var details = $("<details>");
  		 var summary = $("<summary>");
  		 $(summary).append(first)
  		 $(details).append(summary);
  		 $(details).append(last);
  		 $(li).append(details);	
  		 $(sections[i]).replaceWith(li);
  	     }
	 });
	 </script>
       <link rel="stylesheet" href="../../css/pandoc.css">
       <script src="../../js/eBook.js"></script>
</head>
<body>

<nav class="navbar navbar-inverse navbar-fixed-top">
  <ul class="nav navbar-nav">
    <li class="dropdown">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Chapter<span class="caret"></span></a>
      <ul class="dropdown-menu"> 
        <li><a href="../en/index.html">HOME</a></li>
        <li><a href="../en/chapter01/index.html">Chapter 1</a></li>
        <li><a href="../en/chapter02/index.html">Chapter 2</a></li>
        <li><a href="../en/chapter03/index.html">Chapter 3</a></li>
        <li><a href="../en/chapter04/index.html">Chapter 3</a></li>
        <li><a href="../en/chapter05/index.html">Chapter 5</a></li>
        <li><a href="../en/chapter06/index.html">Chapter 6</a></li>
        <li><a href="../en/chapter07/index.html">Chapter 7</a></li>
        <li><a href="../en/chapter08/index.html">Chapter 8</a></li>
        <li><a href="../en/chapter09/index.html">Chapter 9</a></li>
        <li><a href="../en/chapter10/index.html">Chapter 10</a></li>
        <li><a href="../en/chapter11/index.html">Chapter 11</a></li>
        <li><a href="../en/chapter12/index.html">Chapter 12</a></li>
      </ul>
    </li>
    <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Section<span class="caret"></span></a>
	  <ul class="dropdown-menu"> 
                <li><a href="../chapter10/1001.html">10.1 Nonparametric Test for the Location Parameter of Single Population  </a></li>
                <li><a href="../chapter10/1001.html">&nbsp;&nbsp;10.1.1 Sign Test</a></li>
                <li><a href="../chapter10/100102.html">&nbsp;&nbsp;10.1.2 Wilcoxon Signed Rank Sum Test</a></li>
                <li><a href="../chapter10/1002.html">10.2 Nonparametric Test for Location Parameters of Two Populations</a></li>
                <li><a href="../chapter10/1002.html">&nbsp;&nbsp;10.2.1 Independent Samples: Wilcoxon Rank Sum Test</a></li>
                <li><a href="../chapter10/100202.html">&nbsp;&nbsp;10.2.2 Paired Samples: Wilcoxon Signed Rank Sum Test</a></li>
                <li><a href="../chapter10/1003.html">10.3 Nonparametric Test for Location Parameters of Several Populations</a></li>
                <li><a href="../chapter10/1003.html">&nbsp;&nbsp;10.3.1 Completely Randomized Design: Kruskal-Wallis Test</a></li>
                <li><a href="../chapter10/100302.html">&nbsp;&nbsp;10.3.2 Randomized Block Design: Friedman Test</a></li>
                <li><a href="../chapter10/1004.html">10.4 Exercise</a></li>
	  </ul>
    </li>
    <li><a class="navbar-brand" href="http://estat.me" target="_blank">eStat</a></li>
    <li><a class="navbar-brand" href="http://www.estat.me/estat/eStatU/index.html" target="_blank">eStatU</a></li>
    <li><a class="navbar-brand" href="/estat/eLearning/Distribution/index.html" target="_blank">Distribution</a></li>
  </ul>
</nav>

<div class="container-fluid">
  <div class="row">
    <div id="sidebar" class="col-sm-3 col-md2 sidebar">
      <ul>
	<li><a href=""></a>
	  <ul>
            <li><a href="../index.html">HOME</a></li>
	    <li><a href="../chapter01/index.html">Chapter 1</a>
	      <ul>
                <li><a href="../chapter01/0101.html">1.1 Statistics and Data Science</a></li>
                <li><a href="../chapter01/0102.html">1.2 Population and Sample</a></li>
                <li><a href="../chapter01/0103.html">1.3 Variables and Data</a></li>
                <li><a href="../chapter01/0104.html">1.4 Softwares for Statistical Analysis</a></li>
                <li><a href="../chapter01/0105.html">1.5 Exercies</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter02/index.html">Chapter 2</a>
	      <ul>
                <li><a href="../chapter02/0201.html">2.1 Visualization of Qualitative Data</a></li>
                <li><a href="../chapter02/0202.html">2.2 Visualization of Summary Data</a></li>
                <li><a href="../chapter02/0202.html">&nbsp;&nbsp;2.2.1 Summary Data of Categorical Variable</a></li>
                <li><a href="../chapter02/0202.html">&nbsp;&nbsp;2.2.2 Summary Data of Categorical Variable with Group</a></li>
                <li><a href="../chapter02/0203.html">2.3 Visualization of Raw Data</a></li>
                <li><a href="../chapter02/0203.html">&nbsp;&nbsp;2.3.1 Raw Data of Categorical Variable</a></li>
                <li><a href="../chapter02/0203.html">&nbsp;&nbsp;2.3.2 Raw Data of Categorical Variable with Group</a></li>
                <li><a href="../chapter02/0204.html">2.4 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter03/index.html">Chapter 3</a>
	      <ul>
                <li><a href="../chapter03/0301.html">3.1 Visualization of Quantitative Data</a></li> 
                <li><a href="../chapter03/0302.html">3.2 Visualization of Single Quantitative Variable</a></li>
                <li><a href="../chapter03/0302.html">&nbsp;&nbsp;3.2.1 Visualization of Quantitative Data without Group</a></li>
                <li><a href="../chapter03/0302.html">&nbsp;&nbsp;3.2.2 Visualization of Quantitative Data with Group</a></li>
                <li><a href="../chapter03/0303.html">3.3 Visualization of Two Quantitative Variables</a></li>
                <li><a href="../chapter03/0304.html">3.4 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter04/index.html">Chapter 4</a>
	      <ul>
                <li><a href="../chapter04/0401.html">4.1 Frequency Table for Single Variable</a></li>
                <li><a href="../chapter04/0401.html">&nbsp;&nbsp;4.1.1 Frequency Table for Categorical Variable</a></li>
                <li><a href="../chapter04/0401.html">&nbsp;&nbsp;4.1.2 Frequency Table for Quantitative Variable</a></li>
                <li><a href="../chapter04/0402.html">4.2 Contingency Table for Two Variables</a></li>
                <li><a href="../chapter04/0402.html">&nbsp;&nbsp;4.2.1 Contingency Table for Two Categorical Variables</a></li>
                <li><a href="../chapter04/0402.html">&nbsp;&nbsp;4.2.2 Contingency Table for Two Quantitative Variables</a></li>
                <li><a href="../chapter04/040301.html">4.3 Summary Measures for Quantitative Variable</a></li>
                <li><a href="../chapter04/040301.html">&nbsp;&nbsp;4.3.1 Measures of Central Tendency</a></li>
                <li><a href="../chapter04/040302.html">&nbsp;&nbsp;4.3.2 Measures of Dispersion</a></li>
                <li><a href="../chapter04/0404.html">4.4 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter05/index.html">Chapter 5</a>
	      <ul>
                <li><a href="../chapter05/0501.html">5.1 Definition of Probability</a></li>
                <li><a href="../chapter05/0502.html">5.2 Calculation of Probability</a></li>
                <li><a href="../chapter05/0503.html">5.3 Discrete Random Variable</a></li>
		<li><a href="../chapter05/050301.html">&nbsp;&nbsp;5.3.1 Binomial Distribution</a></li>
		<li><a href="../chapter05/050302.html">&nbsp;&nbsp;5.3.2 Poissson Distribution</a></li>
		<li><a href="../chapter05/050303.html">&nbsp;&nbsp;5.3.3 Geometric Distribution</a></li>
		<li><a href="../chapter05/050304.html">&nbsp;&nbsp;5.3.4 Hypergeometric Distribution</a></li>
                <li><a href="../chapter05/0504.html">5.4 Continuous Random Variable</a></li>
		<li><a href="../chapter05/050401.html">&nbsp;&nbsp;5.4.1 Normal Distribution</a></li>
		<li><a href="../chapter05/050402.html">&nbsp;&nbsp;5.4.2 Exponential Distribution</a></li>
                <li><a href="../chapter05/0505.html">5.5 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter06/index.html">Chapter 6</a>
	      <ul>
                <li><a href="../chapter06/0601.html">6.1 Simple Random Sampling</a></li>
                <li><a href="../chapter06/060201.html">6.2 Sampling Distribution of Sample Means and Estimation of the Population Mean</a></li>
                <li><a href="../chapter06/060201.html">&nbsp;&nbsp;6.2.1 Sampling Distribution of Sample Means</a></li>
                <li><a href="../chapter06/060202.html">&nbsp;&nbsp;6.2.2 Estimation of the Population Mean</a></li>
                <li><a href="../chapter06/060301.html">6.3 Sampling Distribution of Sample Variances and Estimation of the Population Variance</a></li>
                <li><a href="../chapter06/060301.html">&nbsp;&nbsp;6.3.1 Sampling Distribution of Sample Variances</a></li>
                <li><a href="../chapter06/060302.html">&nbsp;&nbsp;6.3.2 Estimation of the Population Variance</a></li>
                <li><a href="../chapter06/060401.html">6.4 Sampling Distribution of Sample Proportions and Estimation of the Population Proportion</a></li>
                <li><a href="../chapter06/060401.html">&nbsp;&nbsp;6.4.1 Sampling Distribution of Sample Proportions</a></li>
                <li><a href="../chapter06/060402.html">&nbsp;&nbsp;6.4.2 Estimation of the Population Proportion</a></li>
                <li><a href="../chapter06/0605.html">6.5 Determination of the Sample Size  </a></li>
                <li><a href="../chapter06/0605.html">&nbsp;&nbsp;6.5.1 Determination of the Sample Size to Estimate the Population Mean </a></li>
                <li><a href="../chapter06/0605.html">&nbsp;&nbsp;6.5.2 Determination of the Sample Size to Estimate the Population Proportion</a></li> 
                <li><a href="../chapter06/0606.html">6.6 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter07/index.html">Chapter 7</a>
	      <ul>
                <li><a href="../chapter07/0701.html">7.1 Testing Hypothesis for a Population Mean</a></li>
                <li><a href="../chapter07/0702.html">7.2 Testing Hypothesis for a Population Variance</a></li>
                <li><a href="../chapter07/0703.html">7.3 Testing Hypothesis for a Population Proportion</a></li>
                <li><a href="../chapter07/0704.html">7.4 Testing Hypothesis with α and β simultaneously</a></li>
                <li><a href="../chapter07/0704.html">&nbsp;&nbsp;7.4.1 Type 2 Error and Power of a Test</a></li>
                <li><a href="../chapter07/0704.html">&nbsp;&nbsp;7.4.2 Testing Hypothesis with α and β</a></li>
                <li><a href="../chapter07/0705.html">7.5 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter08/index.html">Chapter 8</a>
	      <ul>
                <li><a href="../chapter08/080101.html">8.1 Testing Hypothesis for Two Population Means</a></li>
                <li><a href="../chapter08/080101.html">&nbsp;&nbsp;8.1.1 Two Independent Samples</a></li>
                <li><a href="../chapter08/080102.html">&nbsp;&nbsp;8.1.2 Paired Sample</a></li>
                <li><a href="../chapter08/0802.html">8.2 Testing Hypothesis for Two Population Variances</a></li>
                <li><a href="../chapter08/0803.html">8.3 Testing Hypothesis for Two Population Proportions</a></li>
                <li><a href="../chapter08/0804.html">8.4 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter09/index.html">Chapter 9</a>
	      <ul>
                <li><a href="../chapter09/0901.html">9.1 Analysis of Variance for Experiments of Single Factor</a></li>
                <li><a href="../chapter09/090101.html">&nbsp;&nbsp;9.1.1 Multiple Comparison</a></li>
                <li><a href="../chapter09/090101.html">&nbsp;&nbsp;9.1.2 Residual Analysis</a></li>
                <li><a href="../chapter09/0902.html">9.2 Design of Experiments for Sampling</a></li>
                <li><a href="../chapter09/0902.html">&nbsp;&nbsp;9.2.1 Completely Randomized Design</a></li>
                <li><a href="../chapter09/0902.html">&nbsp;&nbsp;9.2.2 Randomized Block Design</a></li>
                <li><a href="../chapter09/0903.html">9.3 Analysis of Variance for Experiments of Two Factors</a></li>
                <li><a href="../chapter09/0904.html">9.4 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter10/index.html">Chapter 10</a>
	      <ul>
                <li><a href="../chapter10/1001.html">10.1 Nonparametric Test for the Location Parameter of Single Population  </a></li>
                <li><a href="../chapter10/1001.html">&nbsp;&nbsp;10.1.1 Sign Test</a></li>
                <li><a href="../chapter10/100102.html">&nbsp;&nbsp;10.1.2 Wilcoxon Signed Rank Sum Test</a></li>
                <li><a href="../chapter10/1002.html">10.2 Nonparametric Test for Location Parameters of Two Populations</a></li>
                <li><a href="../chapter10/1002.html">&nbsp;&nbsp;10.2.1 Independent Samples: Wilcoxon Rank Sum Test</a></li>
                <li><a href="../chapter10/100202.html">&nbsp;&nbsp;10.2.2 Paired Samples: Wilcoxon Signed Rank Sum Test</a></li>
                <li><a href="../chapter10/1003.html">10.3 Nonparametric Test for Location Parameters of Several Populations</a></li>
                <li><a href="../chapter10/1003.html">&nbsp;&nbsp;10.3.1 Completely Randomized Design: Kruskal-Wallis Test</a></li>
                <li><a href="../chapter10/100302.html">&nbsp;&nbsp;10.3.2 Randomized Block Design: Friedman Test</a></li>
                <li><a href="../chapter10/1004.html">10.4 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter11/index.html">Chapter 11</a>
	      <ul>
                <li><a href="../chapter11/1101.html">11.1 Goodness of Fit Test</a></li>
                <li><a href="../chapter11/1101.html">&nbsp;&nbsp;11.1.1 Goodness of Fit Test for Categorical Distribution</a></li>
                <li><a href="../chapter11/110102.html">&nbsp;&nbsp;11.1.2 Goodness of Fit Test for Continuous Distribution</a></li>
                <li><a href="../chapter11/1102.html">11.2 Testing Hypothesis for Contingency Table</a></li>
                <li><a href="../chapter11/1102.html">&nbsp;&nbsp;11.2.1 Independence Test</a></li>
                <li><a href="../chapter11/110202.html">&nbsp;&nbsp;11.2.2 Homogeneity Test</a></li>
                <li><a href="../chapter11/1103.html">11.3 Exercise</a></li>
	      </ul>
	    </li>
	    <li><a href="../chapter12/index.html">Chapter 12</a>
	      <ul>
                <li><a href="../chapter12/1201.html">12.1 Correlation Analysis</a></li>
                <li><a href="../chapter12/1202.html">12.2 Simple Linear Regression Analysis</a></li>
                <li><a href="../chapter12/1203.html">12.3 Multiple Linear Regression Analysis</a></li>
                <li><a href="../chapter12/1204.html">12.4 Exercise</a></li>
	      </ul>
	    </li>
	  </ul>
	</li>
      </ul>
    </div>
  </div>
</div>

<div class="col-sm-9 col-sm-offset-3 col-md-10 col-md-offset-2 main">

  <!--***********************************************************************-->
  <h2>Chapter 10. Nonparametric Testing Hypothesis</h2> 
  <p>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      <button type="button" style="width:160px" onclick="moveSection(104)">&#10094; &nbsp;&nbsp;<b>Previous</b></button>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      <button type="button" style="width:160px" onclick="moveSection(106)"><b>Next</b>&nbsp;&nbsp; &#10095;</button>
  <p>
  <h3>10.3 Nonparametric Test for Comparing Locations of Several Populations</h3>
  <p>
  <h6>
      <a href="1003.pdf" target="_blank"><u>[presentation]</u></a>&nbsp;&nbsp;&nbsp;
      <a href="https://youtu.be/iXLAS-UTiIk" target="_blank"><u>[video]</u></a>
  </h6>
  <p>

    <div class="mainTable">
      The testing hypothesis for several population means in Chapter 9 was possible if each population could be 
      assumed to be a normal distribution and has the same population variance. However, the assumption that the 
      population follows a normal distribution may not be true for real-world data, or that there may not be enough 
      data to assume a normal distribution. Alternatively, if data are ordinal such as ranks, then the parametric test 
      is not appropriate. In this case, a nonparametric test is used by converting data into ranks without making 
      assumptions about the population distribution. This section introduces the Kruskal-Wallis test corresponding to 
      the completely randomized design of experiments and the Friedman test corresponding to the randomized block 
      design of experiments in Chapter 9.
      <p>
      Since nonparametric tests are done by using the converted data such as ranks, there may be some loss of 
      information about the data. Therefore, if data are normally distributed, there is no reason to apply a 
      nonparametric test. However, a nonparametric test would be a more appropriate method if data were selected from a 
      population that did not follow a normal distribution.
    </div>
    <p>

  <h4>10.3.1 Completely Randomized Design: Kruskal-Wallis Test</h4>
  <p>

    <div class="mainTable">
      The Kruskal–Wallis test extends the Wilcoxon rank sum test for two populations. Consider the following example.
    </div>
    <p>

    <!------------------------------------------------------------------------------------------------->
    <div class="mainTableGrey">
      <b>Example 10.3.1</b>
         The result of a survey of the job satisfaction by sampling employees of three companies are as follows. 
         From this data, can you say that the three   companies have different job satisfaction? (unit: points out of 100 scores)
      <p>
        <div class="textLeft">Company A    69   67   65   59   </div>
        <div class="textLeft">Company B    56   63   55   </div>
        <div class="textLeft">Company C    71   72   70   </div>
        <div class="textLeft">[Ex] ⇨ eBook ⇨ EX100301_JobSatisfaction.csv</div>
      <p>
      <div class="textL20M20">
        1) Draw a histogram of the data to see whether the comparison of the job satisfaction for the three companies can be made using a parametric test. 
      </div>
      <div class="textL20M20">
        2) Using the Kruskal-Wallis test, which is a nonparametric test, find whether the three companies have 
           the same job satisfaction or not with the significance level of 5%
      </div>
      <div class="textL20M20">
        3) Check the above result of the Kruskal-Wallis test using『eStat』.
      </div>
      <p>
      <b>Answer</b>
      <p>
      <div class="textL20M20">
        1) The parametric method for testing the hypothesis that three population means are the same is 
           the one-way  analysis of variance studied in Chapter 9 and it requires the assumption that 
           the populations are normal distributions. Since the sample sizes are small, \(n_1\) = 4, \(n_2\) = 3,
           \(n_3\) =3, in each of the population respectively we need to examine if each sample data satisfy 
           the normality assumption. 
      </div>
      <p>
      <div class="textL20">
        Enter the data as shown in &lt;Figure 10.3.1&gt; in『eStat』.
      </div>
      <p>
      <table style="width:650px">
        <tr>
          <td>
            <input class="qrBtn" type="image" src="../../QR/EX100301.svg" onclick="window.open(addrStr[33])">
          </td>
          <td>
            <img class="imgFig600400" src="../../Figure/Fig100301.png">
            <div class="figText">&lt;Figure 10.3.1&gt; 『eStat』data input</div>
          </td>
        </tr>
      </table>
      <p>
      <div class="textL20">
        Click the ANOVA icon . Select ‘Score’ as ‘Analysis Var’ and ‘Company’ as ‘by Group’ variable
        in the variable selection box. Then a dot graph with the 95% confidence interval of each population 
        mean will appear as in &lt;Figure 10.3.2&gt;. Company C has the high average of satisfaction scores, 
        followed by Company A and Company B. However, it should be tested if these differences are statistically 
        significant. Clicking the [Histogram] button in the options window below the graph will reveal the
        histogram and its normal distribution curve for each company, as in&lt;Figure 10.3.3&gt;.
      </div>
      <p>
      <img class="imgFig600400" src="../../Figure/Fig100302.svg">
      <div class="figText">&lt;Figure 10.3.2&gt; Dot graph and the confidence interval by company</div>
      <p>
      <img class="imgFig600400" src="../../Figure/Fig100303.svg">
      <div class="figText">&lt;Figure 10.3.3&gt; Histogram by company</div>
      <p>

      <div class="textL20">
        Looking at the histogram, the data are not sufficient to assume that the population follows 
        a normal distribution, because the number of data is so small. In such a case, applying the parametric 
        hypothesis test such as the ANOVA F-test may lead to errors. The hypothesis for this problem is to test 
        whether the location parameters \(\small M_1\), \(\small M_2\), \(\small M_3\) of the three populations are the same or not as follows: 
        <p>
          \(\qquad \small H_0 : M_1 = M_2 = M_3\) <br>
          \(\qquad \small H_1 : \) At least one pair of location parameters is not the same.
        <p>
      </div>
      <p>
      <div class="textL20">
        The Kruskal–Wallis test combines all three samples into a single set of data and calculate ranks 
        of this data. If there is a tie, then the average rank will be assigned. Then the sum of the ranks
        in each sample, \(\small R_1 , R_2 , R_3\), is calculated. The test statistic \(\small H\) for the 
        Kruskal–Wallis test is similar to the \(\small F\)-test by converting sample data into ranks as follows: 
        <p>
          \(\qquad \small H = \frac{12}{n(n+1)} \sum_{j=1}^{3} \frac{R_j^2}{n_j} - 3(n+1)\)
        <p>
        To obtain ranks of the combined sample, it is convenient to arrange the data in ascending order 
        separately and then rank the whole data as shown in Table 10.3.1.
      </div>
      <p>
        <div class="textLeft">Table 10.3.1  A table to calculate the sum of ranks in each sample</div>
      <p>
      <table style="width:600px"> 
        <tr> 
          <th class="thGrey">Sorted Data of Sample 1 </th>
          <th class="thGrey">Sorted Data of Sample 2</th>
          <th class="thGrey">Sorted Data of Sample 3</th>
          <th class="thGrey">Ranks of Sample 1</th>
          <th class="thGrey">Ranks of Sample 2</th>
          <th class="thGrey">Ranks of Sample 3</th>
        </tr>
        <tr> <td class="tdCenter">  </td> <td class="tdCenter">55</td> <td class="tdCenter">  </td> <td class="tdCenter"> </td> <td class="tdCenter">1</td> <td class="tdCenter"> </td> </tr>
        <tr> <td class="tdCenter">  </td> <td class="tdCenter">56</td> <td class="tdCenter">  </td> <td class="tdCenter"> </td> <td class="tdCenter">2</td> <td class="tdCenter"> </td> </tr>
        <tr> <td class="tdCenter">59</td> <td class="tdCenter">  </td> <td class="tdCenter">  </td> <td class="tdCenter">3</td> <td class="tdCenter"> </td> <td class="tdCenter"> </td> </tr>
        <tr> <td class="tdCenter">  </td> <td class="tdCenter">63</td> <td class="tdCenter">  </td> <td class="tdCenter"> </td> <td class="tdCenter">4</td> <td class="tdCenter"> </td> </tr>
        <tr> <td class="tdCenter">65</td> <td class="tdCenter">  </td> <td class="tdCenter">  </td> <td class="tdCenter">5</td> <td class="tdCenter"> </td> <td class="tdCenter"> </td> </tr>
        <tr> <td class="tdCenter">67</td> <td class="tdCenter">  </td> <td class="tdCenter">  </td> <td class="tdCenter">6</td> <td class="tdCenter"> </td> <td class="tdCenter"> </td> </tr>
        <tr> <td class="tdCenter">69</td> <td class="tdCenter">  </td> <td class="tdCenter">  </td> <td class="tdCenter">7</td> <td class="tdCenter"> </td> <td class="tdCenter"> </td> </tr>
        <tr> <td class="tdCenter">  </td> <td class="tdCenter">  </td> <td class="tdCenter">70</td> <td class="tdCenter"> </td> <td class="tdCenter"> </td> <td class="tdCenter">8</td> </tr>
        <tr> <td class="tdCenter">  </td> <td class="tdCenter">  </td> <td class="tdCenter">71</td> <td class="tdCenter"> </td> <td class="tdCenter"> </td> <td class="tdCenter">9</td> </tr>
        <tr> <td class="tdCenter">  </td> <td class="tdCenter">  </td> <td class="tdCenter">72</td> <td class="tdCenter"> </td> <td class="tdCenter"> </td> <td class="tdCenter">10</td> </tr>
        <tr> <td></td> <td></td> <td class="tdCenter">Sum of ranks</td> <td class="tdCenter">\(R_{1}=21\)</td> <td class="tdCenter">\(R_{2}=7\)</td> <td class="tdCenter">\(R_{3}=28\)</td> </tr>
      </table>
      <p>

      <div class="textL20">
        The total sum of ranks is 1 + 2 + \(\cdots\) + 10 = \(\frac{10(10+1)}{2}\) = 55. The sum of ranks for
        sample 1 is \(\small R_1\) = 21, for sample 2 is \(\small R_2\) = 7, and for sample 3 is 
        \(\small R_3\) = 27. When the number of data in each sample is taken into account, if \(\small R_1\),
        \(\small R_2\), and \(\small R_3\) are similar, the null hypothesis that three population location 
        parameters are the same would be accepted. In this example, despite of the small sample size for sample 3,
        \(\small R_3\) is larger thant \(\small R_1\) or \(\small R_2\). Also \(\small R_1\) is larger than 
        \(\small R_2\). Based on these differences, can you conclude that the three population location parameters
        are statistically different? 
        <p>
        In the above example, the \(\small H\) statistic is as follows: 
        <p>
          \(\qquad \small H = \frac{12}{10(10+1)} ( \frac{21^2}{4} + \frac{7^2}{3} + \frac{27^2}{3} ) - 3(10+1) \) = 7.318
        <p>
        If the null hypothesis is true, the distribution of the test statistic should be known to investigate how 
        large a value of \(\small H\) is statistically significant. If \(n\) = 10, the number of cases for ranking 
        {1,2,3, ... , 10} is 10! = 3,628,800. It is not easy to examine all of these possible rankings 
        to create a distribution table of \(\small H\). 『eStatU』 shows the distribution of the Kruskal–Wallis
        for \(n_1\) = 4, \(n_2\) = 3, and \(n_3\) = 3 as shown in &lt;Figure 10.3.4&gt;, and a part of the 
        distribution table as in Table 10.3.2. As shown in the figure, the distribution of \(\small H\) is an 
        asymmetrical distribution.
      </div>
      <p>
      <table style="width:650px">
        <tr>
          <td>
            <input class="qrBtn" type="image" src="../../QR/eStatU98D_TestKruskalD.svg" onclick="window.open(addrStr[117])">
          </td>
          <td>
            <img class="imgFig600400" src="../../Figure/Fig100304.svg">
            <div class="figText">&lt;Figure 10.3.4&gt; Kruskal Wallis H distribution when \(n_1 = 4, n_2 = 3, n_3 = 3\)</div>
          </td>
        </tr>
      </table>
      <p>
      <div class="textLeft">Table 10.3.2  Kruskal Wallis H distribution when \(n_1 = 4, n_2 = 3, n_3 = 3\)</div>
      <p>
      <table style="width:500px"> 
        <tr> 
          <th class="thGrey">Kruskal Wallis H distribution</th>
          <th class="thGrey">\(k = 3\)</th>
        </tr>
        <tr> 
          <th class="thGrey"></th>
          <th class="thGrey">\(n_1 = 4\)</th>
          <th class="thGrey">\(n_2 = 3\)</th>
          <th class="thGrey">\(n_3 = 3\)</th>
        </tr>
        <tr>
          <td class="tdCenter">\(x\)</td>
          <td class="tdCenter">\(P(X = x)\)</td>
          <td class="tdCenter">\(P(X \le x)\)</td>
          <td class="tdCenter">\(P(X \ge x)\)</td>
        </tr>
        <tr>
          <td class="tdCenter">0.018</td>
          <td class="tdCenter">0.0162</td>
          <td class="tdCenter">0.0162</td>
          <td class="tdCenter">1.0000</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">0.045</td>
          <td class="tdCenter">0.0133</td>
          <td class="tdCenter">0.0295</td>
          <td class="tdCenter">0.9838</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(\cdots\)</td>
        </tr>                  
        <tr>
        <tr>
          <td class="tdCenter">5.727</td>
          <td class="tdCenter">0.0048</td>
          <td class="tdCenter">0.9543</td>
          <td class="tdCenter">0.0505</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">5.791</td>
          <td class="tdCenter">0.0095</td>
          <td class="tdCenter">0.9638</td>
          <td class="tdCenter">0.0457</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">5.936</td>
          <td class="tdCenter">0.0019</td>
          <td class="tdCenter">0.9657</td>
          <td class="tdCenter">0.0362</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">5.982</td>
          <td class="tdCenter">0.0076</td>
          <td class="tdCenter">0.9733</td>
          <td class="tdCenter">0.0343</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">6.018</td>
          <td class="tdCenter">0.0019</td>
          <td class="tdCenter">0.9752</td>
          <td class="tdCenter">0.0267</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">6.155</td>
          <td class="tdCenter">0.0019</td>
          <td class="tdCenter">0.9771</td>
          <td class="tdCenter">0.0248</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">6.300</td>
          <td class="tdCenter">0.0057</td>
          <td class="tdCenter">0.9829</td>
          <td class="tdCenter">0.0229</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">6.564</td>
          <td class="tdCenter">0.0033</td>
          <td class="tdCenter">0.9862</td>
          <td class="tdCenter">0.0171</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">6.664</td>
          <td class="tdCenter">0.0010</td>
          <td class="tdCenter">0.9871</td>
          <td class="tdCenter">0.0138</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">6.709</td>
          <td class="tdCenter">0.0029</td>
          <td class="tdCenter">0.9900</td>
          <td class="tdCenter">0.0129</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">6.745</td>
          <td class="tdCenter">0.0038</td>
          <td class="tdCenter">0.9938</td>
          <td class="tdCenter">0.0100</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">7.000</td>
          <td class="tdCenter">0.0019</td>
          <td class="tdCenter">0.9957</td>
          <td class="tdCenter">0.0062</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">7.318</td>
          <td class="tdCenter">0.0019</td>
          <td class="tdCenter">0.9976</td>
          <td class="tdCenter">0.0043</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">7.436</td>
          <td class="tdCenter">0.0010</td>
          <td class="tdCenter">0.9986</td>
          <td class="tdCenter">0.0024</td>
        </tr>                  
        <tr>                   
          <td class="tdCenter">8.018</td>
          <td class="tdCenter">0.0014</td>
          <td class="tdCenter">1.0000</td>
          <td class="tdCenter">0.0014</td>
        </tr>                  
      </table>
      <p>

      <div class="textL20">
        \(\small H\) test is a right tail test and the 5 percentile from the right corresponding to the significance level is 
        approximately \(\small P(X \ge 5.727)\) = 0.0505. Note that there is no exact 5 percentile in case of a discrete 
        distribution. Hence, the decision rule to test the null hypothesis is as follows: 
        <p>
          \(\qquad\) ‘If \(\small H \gt \) 5.727, then reject \(\small H_0\) ’
        <p>
        Since \(\small H\) = 7.318 in this example, we reject \(\small H_0\).
      </div>
      <p>

      <div class="textL20M20">
        3) In 『eStatU』, enter data as &lt;Figure 10.3.5&gt; and click the [Execute] button. Then the sample 
           statistics are calculated and the test result is shown as in &lt;Figure 10.3.6&gt;. The critical line 
           for values containing 5 percentile of the significance level is shown here. For a discrete 
           distribution, the choice of the final rejection region shall be determined by the analyst.
      </div>
      <p>
      <table style="width:650px">
        <tr>
          <td>
            <input class="qrBtn" type="image" src="../../QR/eStatU98D_TestKruskalD.svg" onclick="window.open(addrStr[118])">
          </td>
          <td>
            <img class="imgFig600400" src="../../Figure/Fig100305.png">
            <div class="figText">&lt;Figure 10.3.5&gt; 『eStatU』 Kruskal-Wallis test </div>
          </td>
        </tr>
      </table>
      <p>
        <img class="imgFig600400" src="../../Figure/Fig100306.svg">
        <div class="figText">&lt;Figure 10.3.6&gt; Kruskal-Wallis test</div>
      <p>
      <div class="textL20">
       『eStat』 can also be used to conduct the Kruskal–Wallis \(\small H\) test. Enter data as 
        &lt;Figure 10.3.1&gt; and click the ANOVA icon. Select ‘Score’ as ‘Analysis Var’ and ‘Company’ 
        as ‘by Group’ variable in the variable selection box. Then a dot graph with the 95% confidence interval
        of the population mean in each company will appear as &lt;Figure 10.3.2&gt;. If you press the 
        [Kruskal–Wallis test] button in the options window below the graph, the same test graph and test result
        table will appear as in &lt;Figure 10.3.7&gt;. 
      </div>
      <p>
        <img class="imgFig600400" src="../../Figure/Fig100307.png">
        <div class="figText">&lt;Figure 10.3.7&gt; Result of the Kruskal-Wallis test</div>
    </div>
    <!------------------------------------------------------------------------------------------------->
    <p>

    <div class="mainTable">
      Let us generalize the Kruskal–Wallis \(H\) test described so far with an example. Denote 
      random samples collected independently from the \(k\) populations (at each level of one factor) 
      when their sample sizes are \(n_1 , n_2 , ... , n_k\) as follows: (\(n = n_1 + n_2 + \cdots + n_k\)).
    </div>
    <p>
      <div class="textLeft">Table 10.3.3  Notation for random samples from each level</div>
    <p>
      <table style="width:500px"> 
        <tr> 
          <th class="thGrey">Lebel 1</th>
          <th class="thGrey">Lebel 2</th>
          <th class="thGrey">\(\cdots\)</th>
          <th class="thGrey">Lebel \(k\)</th>
        </tr>
        <tr>
          <td class="tdCenter">\(X_{11}\)</td>
          <td class="tdCenter">\(X_{21}\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(X_{k1}\)</td>
        </tr>
        <tr>
          <td class="tdCenter">\(X_{12}\)</td>
          <td class="tdCenter">\(X_{22}\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(X_{k2}\)</td>
        </tr>
        <tr>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(\cdots\)</td>
        </tr>
        <tr>
          <td class="tdCenter">\(X_{1n_{1}}\)</td>
          <td class="tdCenter">\(X_{2n_{2}}\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(X_{kn_{k}}\)</td>
        </tr>
        <tr>
          <td class="tdCenter">Mean \({\overline X}_{1\cdot}\)</td>
          <td class="tdCenter">Mean \({\overline X}_{2\cdot}\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">Mean \({\overline X}_{k\cdot}\)</td>
          <td class="tdCenter">Total Mean \({\overline X}_{\cdot \cdot}\)</td>
        </tr>
      </table>
      <p>
    
    <p>
    <div class="mainTable">
      The statistical model of the Kruskal-Wallis test is as follows:
      $$
        X_{ij} = \mu + \tau_i +  \epsilon_{ij}, \quad i=1,2,... k; j=1,2,...,n_i \; \text{where} \sum_{i=1}^{k} \tau_i = 0. 
      $$
      <p>
      Here \(\tau_i\) represents the effect of the level \(i\) and \(\epsilon_{ij}\)’s are independent and 
      follow the same continuous distribution. The hypothesis of the Kruskal-Wallis test is as follows:
      $$
        \begin{align}
          H_0 &: \tau_1 = \tau_2 = \cdots = \tau_k \\
          H_1 &: \text{At least one pair of } \tau_i \text{ is not equal.}
        \end{align}
      $$
      For the Kruskal–Wallis test, ranking data for the combined sample must be created. Table 10.3.4 is a 
      notation of ranking data for each level.
    </div>
    <p>
      <div class="textLeft">Table 10.3.4  Notation of ranking data in each level</div>
    <p>
      <table style="width:600px"> 
        <tr> 
          <th></th>
          <th class="thGrey">Lebel 1</th>
          <th class="thGrey">Lebel 2</th>
          <th class="thGrey">\(\cdots\)</th>
          <th class="thGrey">Lebel \(k\)</th>
        </tr>
        <tr>
          <td></td>
          <td class="tdCenter">\(R_{11}\)</td>
          <td class="tdCenter">\(R_{21}\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(R_{k1}\)</td>
        </tr>
        <tr>
          <td></td>
          <td class="tdCenter">\(R_{12}\)</td>
          <td class="tdCenter">\(R_{22}\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(R_{k2}\)</td>
        </tr>
        <tr>
          <td></td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(\cdots\)</td>
        </tr>
        <tr>
          <td></td>
          <td class="tdCenter">\(R_{1n_{1}}\)</td>
          <td class="tdCenter">\(R_{2n_{2}}\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">\(R_{kn_{k}}\)</td>
        </tr>
        <tr>
          <td class="tdLeft">Sum of ranks</td>
          <td class="tdCenter">Sum \({R}_{1\cdot}\)</td>
          <td class="tdCenter">Sum \({R}_{2\cdot}\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">Sum \({R}_{k\cdot}\)</td>
        </tr>
        <tr>
          <td class="tdLeft">Mean of ranks</td>
          <td class="tdCenter">Mean \({\overline R}_{1\cdot}\)</td>
          <td class="tdCenter">Mean \({\overline R}_{2\cdot}\)</td>
          <td class="tdCenter">\(\cdots\)</td>
          <td class="tdCenter">Mean \({\overline R}_{k\cdot}\)</td>
          <td class="tdCenter">Total Mean \({\overline R}_{\cdot \cdot} = \frac{n+1}{2}\)</td>
        </tr>
      </table>
    <p>

    <div class="mainTable">
      The sum of squares for the one-way analysis of variance studied in Chapter 9 by using the ranking data in 
      Table 10.3.4 are as follows:
      $$
        \begin{align}
          SST  & = \sum_{i=1}^k \sum_{j=1}^{n_i} ( R_{ij} - {\overline R}_{\cdot \cdot} )^2 = \sum_{k=1}^n (k -{\overline R}_{\cdot \cdot} )^2 = n(n+1)(n-1) \\
          SSTr & = \sum_{i=1}^k \sum_{j=1}^{n_i} ( {\overline R}_{i \cdot} - {\overline R}_{\cdot \cdot} )^2 \\
          SSE  & = SST - SSTr \\
        \end{align}
      $$
      Also, the statistic for the \(F\)-test is as follows: 
      $$
        F = \frac {MSTr}{MSE} = \frac { \frac{SSTr}{k-1}} {\frac{SSE}{n-k}} = \frac {\frac{SSTr}{k-1}} {\frac{SST-SSTr}{n-k}} = \frac{\frac{n-k}{k-1}} {\frac{SST}{SSTr} -1}
      $$
      Since \(SST\) is a constant, the statistic for the \(F\)-test is proportional to \(SSTr\). 
      <p>
      The statistic for the Kruskal-Wallis test \(H\) is proportional to \(SSTr\) as follows: 
      $$
        \begin{align}
          H  & = \frac {12}{n(n+1)} \sum_{i=1}^{k} n_{i} ( {\overline {R}}_{i \cdot} - {\overline {R}}_{\cdot \cdot} )^{2} \\
             & = \frac{12}{n(n+1)} \sum_{i=1}^{k} {R}_{i \cdot}^2 - 3(n+1) \\
        \end{align}
      $$
      <p>
      The multiplication constant \( \frac{12}{n(n+1)}\) in the definition of \(H\) statistics is intended 
      to ensure that the statistic follows approximately the chi-square distribution with \(k-1\) degrees of 
      freedom.
      <p>
      The distribution of the Kruskal-Wallis test statistic \(H\), denoted as \(h(n_1 ,n_2 , ... , n_k )\), 
      can be obtained by considering all possible cases of ranks {1, 2, ,\(n\)} which is \(n!\). 『eStatU』 
      provides the table of \(h(n_1 ,n_2 , ... , n_k )\) up to \(n\) = 10. \(h(n_1 ,n_2 , ... , n_k )_&alpha;\)
      denotes the right end 100\(\times &alpha;\) percentile, but it might not have the exact value of this 
      percentile, because \(h(n_1 ,n_2 , ... , n_k )\) is a discrete distribution. In this case, the middle of 
      two adjacent values of 100\(\times &alpha;\) percentile is often used. The decision rule of the 
      Kruskal-Wallis test is as Table 10.3.5. 
    </div>
    <p>
      <div class="textLeft">Table 10.3.5  Kruskal-Wallis test </div>
    <p>
      <table style="width:700px"> 
        <tr> 
          <th class="thGrey">Hypothesis</th>
          <th class="thGrey">Decision Rule<br>Test Statistic \(H\)</th>
        </tr>
        <tr style="height:40px">
          <td class="tdLeft">\( \; H_0 : {\tau}_1 = {\tau}_2 = \cdots = {\tau}_k \)<br>\( \; H_1 : \text{At least one pair of } {\tau}_i \) is not equal</td>
          <td class="tdLeft">If \( H > h(n_1 , n_2 , ... n_k )_{&alpha;} \), then reject \( H_0 \) </td>
      </table>
    <p>

    <div class="mainTableYellow">
      <b>☞ If there are tied values in the combined sample, assign the average of ranks. </b>
    </div>
    <p>

    <div class="mainTable">
      The distribution of the Kruskal-Wallis \(H\) statistic is independent of a population distribution. 
      In other words, the Kruskal-Wallis test is a distribution-free test. 
      <p>
      If the null hypothesis is true and the sample size is large enough, the test statistic \(H\) is approximated
      by the chi-square distribution with \(k-1\) degrees of freedom. Table 10.3.6 summarizes the decision rule 
      for the Kruskal-Wallis test in case of large samples.
    </div>
    <p>
      <div class="textLeft">Table 10.3.6  Kruskal-Wallis test in case of large samples.</div>
    <p>
      <table style="width:700px"> 
        <tr> 
          <th class="thGrey">Hypothesis</th>
          <th class="thGrey">Decision Rule<br>Test Statistic \(H\)</th>
        </tr>
        <tr style="height:40px">
          <td class="tdLeft">\( \; H_0 : {\tau}_1 = {\tau}_2 = \cdots = {\tau}_k \)<br>\( \; H_1 : \text{At least one pair of } {\tau}_i \) is not equal</td>
          <td class="tdLeft">If \( H > {\chi}^2_{k-1; &alpha;} \), then reject \( H_0 \) </td>
      </table>
      <p>

    <div class="mainTable">
      If there is a tie in the combined sample, the average rank is assigned to each data. In this case, the 
      statistic \(H\) shall be modified as follows:
      $$
        H' =  \frac{H} {1 - \sum_{j=1}^{g} \frac{T_j}{n^3 - n} } 
      $$
      Here  \(g\)= (number of tied groups), \(T_j = \sum_{j=1}^{g} {t}_{j} ({t}_{j}-1)({t}_{j}+1) \) where
      \(t_j\) = (the size of the \(j^{th}\) tie group, i.e., the number of observations in the tie group). 
      If there is no tie, the size of the \(j^{th}\) tie group is 1 and \(t_j\) = 1. 
    </div>
    <p>

    <!------------------------------------------------------------------------------------------------->
    <div class="mainTablePink">
      <table style="width:650px">
        <tr>
          <td>
            <input class="qrBtn" type="image" src="../../QR/eStatU98D_TestKruskalD.svg" onclick="window.open(addrStr[118])">
          </td>
          <td>
            <b>Practice 10.3.1</b>
            A bread maker wants to compare the three new mixing methods of ingredients. 15 breads were made 
            by each mixing method (A, B, C) of 5 pieces, and a group of judges who did not know the difference 
            in material mixing ratio gave the following points. Test the null hypothesis that there is no difference 
            in taste according to the mixing methods at the significance level of 0.05.
            <p>
            <div class="textLeft">Mixing ratio:</div>
            <div class="textLeft">Method A:	   72   88   70   87   71</div>
            <div class="textLeft">Method B:	   85   89   86   82   90</div>
            <div class="textLeft">Method C:	   94   94   88   87   89</div>
            <div class="textLeft">[Ex] ⇨ eBook ⇨ PR100301_ScoreByMixingMethod.csv</div>
          </td>
        </tr>
      </table>
    </div>
    <!------------------------------------------------------------------------------------------------->
    <p>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      <button type="button" style="width:160px" onclick="moveSection(104)">&#10094; &nbsp;&nbsp;<b>Previous</b></button>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      <button type="button" style="width:160px" onclick="moveSection(106)"><b>Next</b>&nbsp;&nbsp; &#10095;</button>
    <p>

</div>


    
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="https://maxcdn.bootstrapcdn.com/js/ie10-viewport-bug-workaround.js"></script>
    <script>
        //document.getElementById('sidebar').getElementsByTagName('ul')[0].className += "nav nav-sidebar";
        
        /* ajust the height when click the toc
           the code is from https://github.com/twbs/bootstrap/issues/1768
        */
        var shiftWindow = function() { scrollBy(0, -50) };
        window.addEventListener("hashchange", shiftWindow);
        function load() { if (window.location.hash) shiftWindow(); }
        
        /*add Bootstrap styles to tables*/
        var tables = document.getElementsByTagName("table");
        for(var i = 0; i < tables.length; ++i){
            tables[i].className += "table table-bordered table-hover";
        }
    </script>

</body>
</html>

